{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIfMZ4YecsCnnAbNZflPln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerner-lab/gee_tutorials/blob/main/Crop_Map_Argentina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Cropland mapping with Google Earth Engine\n",
        "Google Earth Engine (GEE) is a cloud-based platform for interacting with and analyzing petabytes of satellite and other Earth data sets. GEE can be used with the Javascript browser-based code editor (https://code.earthengine.google.com) or the Python API. The main benefit of GEE is that it allows you to access huge remote sensing data sets and perform analysis entirely on Google's infrastructure without having to download files to install libraries on your own computer... for free!\n",
        "\n",
        "This tutorial shows how to use the GEE Python API to create a cropland classification map.\n",
        "1.   define a region of interest (ROI)\n",
        "1.   load training and validation labels\n",
        "1.   load satellite data sets and make cloud-free composite\n",
        "1.   train a random forest classifier\n",
        "1.   apply the trained classifier to generate a cropland map\n",
        "1.   generate performance metrics for training and validation subsets\n",
        "1.   export classified map to Google Drive\n",
        "\n",
        "To run this Colab notebook, you will need a Google Earth Engine account (https://signup.earthengine.google.com/#!/).\n",
        "\n",
        "You will also need a Google Drive account to **save a copy of this notebook** so that you can save your changes. Before you get started, click File > Save a Copy in Drive, then rename the file using a name of your choice (e.g., Hannah-Crop-Map-Argentina).\n",
        "\n",
        "\n",
        "Acknowledgment: Some of this tutorial was adapted from the [Rapid Classification of Croplands](https://developers.google.com/earth-engine/tutorials/community/classify-maizeland-ng) tutorial in the Google Earth Engine documentation."
      ],
      "metadata": {
        "id": "uq3r9BUvpMpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up your environment"
      ],
      "metadata": {
        "id": "G_HGUw9Wr0AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Google Earth Engine API is already installed by default in the Colab environment. We need to authenticate to use our GEE account."
      ],
      "metadata": {
        "id": "sCB9WtF5r5ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!earthengine authenticate"
      ],
      "metadata": {
        "id": "yoEd6UoBr5CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can import the Earth Engine API and initialize it."
      ],
      "metadata": {
        "id": "B7ZzIRtTsiNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "ITFjqOgXrvyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll install `geemap`, a python library that provides useful functions for the GEE Python API (https://github.com/giswqs/geemap)\n",
        "\n",
        "NOTE: You may get an error in this step that says, \"You must restart the runtime in order to use newly installed versions.\" This is a known issue - you will need to click the \"Restart Runtime\" button and re-run the steps from the beginning (i.e., you will need to authenticate twice)."
      ],
      "metadata": {
        "id": "S9KxDPnytPBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geemap"
      ],
      "metadata": {
        "id": "_amDS-LAsv6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've installed geemap, we can import the library to use it in our notebook."
      ],
      "metadata": {
        "id": "BUfLlHv7tmF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geemap"
      ],
      "metadata": {
        "id": "WGTVHypzsunT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying the map"
      ],
      "metadata": {
        "id": "hzOJwI1MtzJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GEE enables you to visualize your data and outputs on a map using `ipyleaflet`, `folium` or other python libraries for map visualization. The `geemap` library provides useful wrapper functions for visualizing the map in just a couple of lines."
      ],
      "metadata": {
        "id": "m8hZdRv0t5fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a new map\n",
        "Map = geemap.Map() \n",
        "\n",
        "# We can set the map options, e.g., to show the satellite basemap\n",
        "Map.setOptions('SATELLITE') \n",
        "\n",
        "# Display the Map object\n",
        "Map "
      ],
      "metadata": {
        "id": "5rMVMmeZtjiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a region of interest\n",
        "\n",
        "We will define Buenos Aires province as our region of interest."
      ],
      "metadata": {
        "id": "k1X9pOTBuBjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import admin1 boundaries feature collection\n",
        "admin1 = ee.FeatureCollection(\"FAO/GAUL/2015/level1\");\n",
        "\n",
        "# Apply filter where admin0 name is Argentina and add it to the map\n",
        "argentina = admin1.filter(ee.Filter.eq('ADM0_NAME', 'Argentina'));\n",
        "Map.addLayer(argentina, {}, 'Argentina province boundaries')\n",
        "\n",
        "buenosaires = admin1.filter(ee.Filter.eq('ADM1_NAME', 'Buenos Aires'));\n",
        "Map.addLayer(buenosaires, {}, 'Buenos Aires province boundaries')\n",
        "\n",
        "Map.centerObject(argentina, 6)\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "VauuKhBLtuPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new map object\n",
        "Map = geemap.Map() \n",
        "Map.setOptions('SATELLITE') \n",
        "\n",
        "# Convert the Buenos Aires boundary feature collection to a line for map display\n",
        "border = ee.Image().byte().paint(featureCollection=buenosaires, color=1, width=3)\n",
        "\n",
        "# Display the map\n",
        "Map.centerObject(buenosaires, 6)\n",
        "Map.addLayer(border, {}, 'Buenos Aires province border')\n",
        "Map"
      ],
      "metadata": {
        "id": "E0OQi3W_z5A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import labeled data\n",
        "\n",
        "We are going to use a labeled dataset of nearly 1000 points created by NASA Harvest available at `users/hkerner/buenos-aires-crop-labels`. These points were randomly sampled from a rectangular bounding box containing Buenos Aires province and labeled by two labelers in Collect Earth Online. \n",
        "\n",
        "Each point has an attribute called `subset` which indicates whether the point belongs to the training (70% of points) or validation (30% of points) subset and a `class` attribute which provides a label of crop or non-crop."
      ],
      "metadata": {
        "id": "hqV0-Va-0jpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's visualize the points on the map colored by training (purple) and validation (yellow) subsets."
      ],
      "metadata": {
        "id": "7VVs99zs8bB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = ee.FeatureCollection('users/hkerner/buenos-aires-crop-labels')\n",
        "\n",
        "training_pts = samples.filter(ee.Filter.eq('subset', 'train'))\n",
        "val_pts = samples.filter(ee.Filter.eq('subset', 'val'))\n",
        "\n",
        "Map.addLayer(training_pts, {'color': 'purple'}, 'Training points')\n",
        "Map.addLayer(val_pts, {'color': 'yellow'}, 'Validation points')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "R_XJZ1L4vaM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the points according to their label. We'll color crop points in green and non-crop points in red.\n",
        "\n",
        "Notice how there are a lot more non-crop points than crop and all of the points in the ocean are labeled non-crop (of course!). You can zoom in on the map to see the satellite data correpsonding with each label. See if you agree with the labels assigned for some of the points!"
      ],
      "metadata": {
        "id": "iyyHmlwj8iwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_pts = samples.filter(ee.Filter.eq('class', 'Crop'))\n",
        "noncrop_pts = samples.filter(ee.Filter.eq('class', 'Non-crop'))\n",
        "\n",
        "Map.addLayer(crop_pts, {'color': 'green'}, 'Crop points')\n",
        "Map.addLayer(noncrop_pts, {'color': 'red'}, 'Non-crop points')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "H418AlNT6qQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the satellite data\n",
        "\n",
        "We will create a cloud-free composite of Sentinel-2 images to use as the input for our classifier. \n",
        "\n",
        "Sentinel-2 is a frequently-used Earth observation satellite that has 10m resolution and 5-day revisit frequency. You can read more about the dataset in the [GEE catalog](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED?hl=en)."
      ],
      "metadata": {
        "id": "udBju5lI-Pzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code defines and applies functions for creating a cloud-free composite. It is based on this demo in the [GEE python documentation](https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless)."
      ],
      "metadata": {
        "id": "aZeY9ePQZMUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter settings for cloud masking\n",
        "START_DATE = ee.Date('2020-04-01')\n",
        "END_DATE = ee.Date('2021-03-31')\n",
        "CLOUD_FILTER = 60\n",
        "CLD_PRB_THRESH = 50\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50"
      ],
      "metadata": {
        "id": "rXLFjklKEBDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    # Import and filter S2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
        "\n",
        "    # Import and filter s2cloudless.\n",
        "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date))\n",
        "\n",
        "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr_col,\n",
        "        'secondary': s2_cloudless_col,\n",
        "        'condition': ee.Filter.equals(**{\n",
        "            'leftField': 'system:index',\n",
        "            'rightField': 'system:index'\n",
        "        })\n",
        "    }))"
      ],
      "metadata": {
        "id": "M7vnJA4D2O-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2_sr_cld_col_eval = get_s2_sr_cld_col(buenosaires, START_DATE, END_DATE)"
      ],
      "metadata": {
        "id": "KUUPfYgs2Pmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cloud_bands(img):\n",
        "    # Get s2cloudless image, subset the probability band.\n",
        "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "    # Condition s2cloudless by the probability threshold value.\n",
        "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "\n",
        "    # Add the cloud probability layer and cloud mask as image bands.\n",
        "    return img.addBands(ee.Image([cld_prb, is_cloud]))"
      ],
      "metadata": {
        "id": "hDNiTL8o2Rrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_shadow_bands(img):\n",
        "    # Identify water pixels from the SCL band.\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
        "    SR_BAND_SCALE = 1e4\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
        "\n",
        "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
        "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "\n",
        "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
        "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))"
      ],
      "metadata": {
        "id": "8UXqTZsk2Tb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cld_shdw_mask(img):\n",
        "    # Add cloud component bands.\n",
        "    img_cloud = add_cloud_bands(img)\n",
        "\n",
        "    # Add cloud shadow component bands.\n",
        "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
        "\n",
        "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
        "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
        "\n",
        "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
        "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
        "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
        "        .rename('cloudmask'))\n",
        "\n",
        "    # Add the final cloud-shadow mask to the image.\n",
        "    return img_cloud_shadow.addBands(is_cld_shdw)"
      ],
      "metadata": {
        "id": "tL-FUqJa2V1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2_sr_cld_col = get_s2_sr_cld_col(buenosaires, START_DATE, END_DATE)"
      ],
      "metadata": {
        "id": "eIRAIMjq2Xvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_cld_shdw_mask(img):\n",
        "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
        "    not_cld_shdw = img.select('cloudmask').Not()\n",
        "\n",
        "    # Subset reflectance bands and update their masks, return the result.\n",
        "    return img.select('B.*').updateMask(not_cld_shdw)"
      ],
      "metadata": {
        "id": "RkACAdSn5jnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2_sr_median = (s2_sr_cld_col.map(add_cld_shdw_mask)\n",
        "                             .map(apply_cld_shdw_mask)\n",
        "                             .median())"
      ],
      "metadata": {
        "id": "yCPLvL_f5kGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of this preprocessing is a cloud-free Sentinel-2 mosaic consisting of the median values across all observations acquired over the one year period from April 2020 to April 2021."
      ],
      "metadata": {
        "id": "E2HpQIpPZ9_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map.addLayer(border, {}, 'Buenos Aires province border')\n",
        "\n",
        "# Add layers to the map.\n",
        "Map.addLayer(s2_sr_median,\n",
        "                {'bands': ['B11', 'B8', 'B3'], 'min': 225, 'max': 4000, 'gamma': 1.1},\n",
        "                'S2 cloud-free mosaic')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "M9EV3Mjy5mXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "Now that we have our input data (Sentinel-2 mosaic) and our labels (crop and non-crop labels) with training and validation subsets, we can train the Random Forest classifier using the training data points. Then we will use the trained model to predict all pixels in the Buenos Aires ROI as either crop or non-crop. Finally, we will assess the performance metrics for the training and validation subsets."
      ],
      "metadata": {
        "id": "trOzTfFN8zO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify and select bands that will be used in the classification.\n",
        "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
        "\n",
        "imageCl = s2_sr_median.select(bands)\n",
        "\n",
        "# Overlay the training points on the imagery to get a training sample; include\n",
        "# the crop classification property ('class') in the sample feature collection.\n",
        "training = imageCl.sampleRegions(\n",
        "                     collection=training_pts,\n",
        "                     properties=['binaryclas'],\n",
        "                     scale=30,\n",
        "                     tileScale=8).filter(ee.Filter.neq(\n",
        "                       'B1', None)); # Remove null pixels."
      ],
      "metadata": {
        "id": "fYTz0Shn52yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a random forest classifier with default parameters.\n",
        "trainedRf = ee.Classifier.smileRandomForest(numberOfTrees=10).train(features=training,\n",
        "                                                                    classProperty='binaryclas',\n",
        "                                                                    inputProperties=bands)"
      ],
      "metadata": {
        "id": "xyp9DPqJ9QF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the trained model to the entire Buenos Aires region\n",
        "classifiedRf = imageCl.select(bands).classify(trainedRf)"
      ],
      "metadata": {
        "id": "cWPYyVTo9iLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainedRf_clipped = classifiedRf.clip(buenosaires.clip())"
      ],
      "metadata": {
        "id": "bMzDkKDnBZx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output of the training classification to the map.\n",
        "classVis = {'min': 0, 'max': 1, 'palette': ['484848', '00ff00']}\n",
        "Map.addLayer(trainedRf_clipped, classVis, 'Classes (RF)')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "avDDL-Pq9-f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the confusion matrix for the training data\n",
        "trainAccuracyRf = trainedRf.confusionMatrix()\n",
        "\n",
        "# Print model accuracy results.\n",
        "print('##### TRAINING ACCURACY #####')\n",
        "print('RF: overall accuracy:', trainAccuracyRf.accuracy().getInfo())\n",
        "print('RF: user accuracy:', trainAccuracyRf.consumersAccuracy().getInfo())\n",
        "print('RF: producer accuracy:', trainAccuracyRf.producersAccuracy().getInfo())"
      ],
      "metadata": {
        "id": "fM1Lbc7c9iRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the error matrix for the training set\n",
        "print('RF: error matrix:', trainAccuracyRf.getInfo())"
      ],
      "metadata": {
        "id": "9SCuoKNhM4vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract band pixel values for validation points.\n",
        "validation = imageCl.sampleRegions(\n",
        "                       collection= val_pts,\n",
        "                       properties= ['binaryclas'],\n",
        "                       scale= 10,\n",
        "                       tileScale= 8\n",
        "                     ).filter(ee.Filter.neq('B1', None)) # Remove null pixels."
      ],
      "metadata": {
        "id": "BEr5_KbCB-hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the validation data.\n",
        "validatedRf = validation.classify(trainedRf)"
      ],
      "metadata": {
        "id": "0yIeZwH8CfB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the validation error matrix and accuracy for both classifiers by\n",
        "# using the \"confusionMatrix\" function to generate metrics on the\n",
        "# resubstitution accuracy.\n",
        "\n",
        "validationAccuracyRf = validatedRf.errorMatrix('binaryclas', 'classification')\n",
        "\n",
        "# Print validation accuracy results.\n",
        "print('##### VALIDATION ACCURACY #####')\n",
        "print('RF: overall accuracy: ', validationAccuracyRf.accuracy().getInfo())\n",
        "print('RF: user accuracy:', validationAccuracyRf.consumersAccuracy().getInfo())\n",
        "print('RF: producer accuracy:', validationAccuracyRf.producersAccuracy().getInfo())\n",
        "\n",
        "print('RF: error matrix: ', validationAccuracyRf.getInfo())"
      ],
      "metadata": {
        "id": "ePhqnMbpL95N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the classified map\n",
        "\n",
        "We can export the classified map to Google Drive so that we can use it for downstream analysis (e.g., area estimation, yield prediction, conditions, etc.)."
      ],
      "metadata": {
        "id": "kYjMs5OnbSdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export classified map (RF) to Google Drive; alter the command to export to\n",
        "# other endpoints.\n",
        "mytask = ee.batch.Export.image.toDrive(\n",
        "  image= trainedRf_clipped.byte(),\n",
        "  description= 'cropland-argentina-rf-20220906',\n",
        "  scale= 10,\n",
        "  region= buenosaires.geometry(),\n",
        "  maxPixels= 1e13,\n",
        "  crs='EPSG:32718')\n",
        "\n",
        "mytask.start()"
      ],
      "metadata": {
        "id": "mu7X7qSTCfF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}